{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "psasaw2"
		},
		"AzureBlobStorage1_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'AzureBlobStorage1'"
		},
		"psasaw2-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'psasaw2-WorkspaceDefaultSqlServer'"
		},
		"LA_pskv_properties_typeProperties_baseUrl": {
			"type": "string",
			"defaultValue": "https://pskv-3.vault.azure.net/"
		},
		"psasaw2-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://psdlsg02.dfs.core.windows.net"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/AzureBlobStorage1')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobStorage",
				"typeProperties": {
					"connectionString": "[parameters('AzureBlobStorage1_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/LA_psadbw')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureDatabricks",
				"typeProperties": {
					"domain": "https://adb-7432988447461131.11.azuredatabricks.net",
					"accessToken": {
						"type": "AzureKeyVaultSecret",
						"store": {
							"referenceName": "LA_pskv",
							"type": "LinkedServiceReference"
						},
						"secretName": "Databricks-Azure-Synapse-Token"
					},
					"existingClusterId": "1029-151818-oiz4tb0"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]",
				"[concat(variables('workspaceId'), '/linkedServices/LA_pskv')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/LA_pskv')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureKeyVault",
				"typeProperties": {
					"baseUrl": "[parameters('LA_pskv_properties_typeProperties_baseUrl')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/psasaw2-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('psasaw2-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/psasaw2-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('psasaw2-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/dbms')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "--\n-- Schemas - stage, active & analytics\n-- There are three schemas named active, stage and analytics...\n--\n\n-- Drop schema\nIF EXISTS (\n\t\tSELECT *\n\t\tFROM sys.schemas\n\t\tWHERE name = 'stage'\n\t\t)\n\tDROP SCHEMA [stage]\nGO\n\n-- Add schema\nCREATE SCHEMA [stage] AUTHORIZATION [dbo]\nGO\n\n-- Drop schema\nIF EXISTS (\n\t\tSELECT *\n\t\tFROM sys.schemas\n\t\tWHERE name = 'active'\n\t\t)\n\tDROP SCHEMA [active]\nGO\n\n-- Add schema\nCREATE SCHEMA [active] AUTHORIZATION [dbo]\nGO\n\n-- Drop schema\nIF EXISTS (\n\t\tSELECT *\n\t\tFROM sys.schemas\n\t\tWHERE name = 'analytics'\n\t\t)\n\tDROP SCHEMA [analytics]\nGO\n\n-- Add schema\nCREATE SCHEMA [analytics] AUTHORIZATION [dbo]\nGO\n\n\n\n\n-- The customer acquistion data table in the stage schema is defined with variable length character fields. \n-- That way, the insertion of data from a Synapse Pipeline copy activity never fails. \n\n-- Drop stage table\nIF EXISTS (\n\t\tSELECT *\n\t\tFROM sys.objects\n\t\tWHERE object_id = OBJECT_ID(N'[stage].[customer_acquistion_data]')\n\t\t\tAND type IN (N'U')\n\t\t)\n\tDROP TABLE [stage].[customer_acquistion_data]\nGO\n\n-- Create stage table\nCREATE TABLE [stage].[customer_acquistion_data] (\n\t[customer_id] VARCHAR(64) NULL\n\t,[relationship_manager_id] VARCHAR(64) NULL\n\t,[last_updated] VARCHAR(64) NULL\n\t,[deposit_amount] VARCHAR(64) NULL\n\t)\nWITH ( CLUSTERED COLUMNSTORE INDEX )\nGO\n\n\n\n\n--\n-- Table - current watermark\n-- The watermark table keeps track of the last run date.\n\n-- Drop stage table if it exists\nIF EXISTS (\n\t\tSELECT *\n\t\tFROM sys.objects\n\t\tWHERE object_id = OBJECT_ID(N'[stage].[current_watermark]')\n\t\t\tAND type IN (N'U')\n\t\t)\n\tDROP TABLE [stage].[current_watermark]\nGO\n\n-- Create stage table\nCREATE TABLE [stage].[current_watermark] ([process_date_hour] DATETIME NOT NULL)\nGO\n\n-- Clear any existing data\nTRUNCATE TABLE [stage].[current_watermark]\nGO\n\n-- Add data to control table\nINSERT INTO [stage].[current_watermark]\nVALUES ('20210101 00:00:00')\nGO\n\n\n\n\n\n--\n-- Table - active customer acquisition data\n-- On the other hand, the customer acquistion data table in the active schema is correctly typed. \n\n-- Drop active table\nIF EXISTS (\n\t\tSELECT *\n\t\tFROM sys.objects\n\t\tWHERE object_id = OBJECT_ID(N'[active].[customer_acquistion_data]')\n\t\t\tAND type IN (N'U')\n\t\t)\n\tDROP TABLE [active].[customer_acquistion_data]\nGO\n\n-- Create active table\nCREATE TABLE [active].[customer_acquistion_data] (\n\t[customer_id] INT NOT NULL\n\t,[relationship_manager_id] INT NOT NULL\n\t,[last_updated] DATE NOT NULL\n\t,[deposit_amount] DECIMAL NOT NULL\n\t)\nWITH  \n  (   \n    DISTRIBUTION = HASH (customer_id),  \n    CLUSTERED COLUMNSTORE INDEX\n  )  \nGO\n\n\n\n--\n-- Stored Proc. - Increment water mark\n-- The increment watermark stored procedure updates the process date by one day each time it is called. \n-- Please see the code below for the definition.\n--\n-- Drop procedure\nIF EXISTS (\n\t\tSELECT *\n\t\tFROM sys.procedures\n\t\tWHERE name = 'increment_watermark'\n\t\t)\n\tDROP PROCEDURE [stage].[increment_watermark]\nGO\n\n-- Create procedure\nCREATE PROCEDURE [stage].[increment_watermark]\nAS\nBEGIN\n\tUPDATE [stage].[current_watermark]\n\tSET [process_date_hour] = DATEADD(dd, 1, [process_date_hour])\nEND\nGO\n\n\n\n\n\n\n--\n-- View - formatted stage data\n-- The cleaned customer acquistion data view tries to cast the variable length character data in the \n-- stage table into strongly typed fields that are compatible with the target table.\n\n-- Drop view\nIF EXISTS (\n\t\tSELECT *\n\t\tFROM sys.objects\n\t\tWHERE name = OBJECT_ID(N'[stage].[vw_cleaned_customer_acquistion_data]')\n\t\t)\n\tDROP VIEW [stage].[vw_cleaned_customer_acquistion_data]\nGO\n\n-- Create view\nCREATE VIEW [stage].[vw_cleaned_customer_acquistion_data]\nAS\nSELECT try_cast([customer_id] AS INT) AS customer_id\n\t,try_cast([relationship_manager_id] AS INT) AS relationship_manager_id\n\t,try_cast([last_updated] AS DATE) AS [date]\n\t,try_cast([deposit_amount] AS DECIMAL) AS deposit_amount\nFROM [stage].[customer_acquistion_data]\nGO\n\n--\n-- Stored Proc. - upsert customer acquisition data\n-- The upsert customer acquisition data stored procedure uses the MERGE statement \n-- to execute an update on matching records and an insert for unmatched records.\n\n-- Drop procedure\nIF EXISTS (\n\t\tSELECT *\n\t\tFROM sys.procedures\n\t\tWHERE name = 'upsert_customer_acquistion_data'\n\t\t)\n\tDROP PROCEDURE [stage].[upsert_customer_acquistion_data]\nGO\n\n-- Create procedure\nCREATE PROCEDURE [stage].[upsert_customer_acquistion_data]\nAS\nBEGIN\n\t-- Set no count\n\tSET NOCOUNT ON\n\n\t-- Merge the clean stage data with active table\n\tMERGE [active].[customer_acquistion_data] AS trg\n\tUSING (\n\t\tSELECT *\n\t\tFROM [stage].[vw_cleaned_customer_acquistion_data]\n\t\t) AS src\n\t\tON src.[date] = trg.[last_updated]\n\t\t\tAND src.[relationship_manager_id] = trg.[relationship_manager_id]\n\t\t\tAND src.[customer_id] = trg.[customer_id]\n\t\t\t-- Update condition\n\tWHEN MATCHED\n\t\tTHEN\n\t\t\tUPDATE\n\t\t\tSET [customer_id] = src.[customer_id]\n\t\t\t\t,[relationship_manager_id] = src.[relationship_manager_id]\n\t\t\t\t,[last_updated] = src.[date]\n\t\t\t\t,[deposit_amount] = src.[deposit_amount]\n\t\t\t\t-- Insert condition\n\tWHEN NOT MATCHED BY TARGET\n\t\tTHEN\n\t\t\tINSERT (\n\t\t\t\t[customer_id]\n\t\t\t\t,[relationship_manager_id]\n\t\t\t\t,[last_updated]\n\t\t\t\t,[deposit_amount]\n\t\t\t\t)\n\t\t\tVALUES (\n\t\t\t\tsrc.[customer_id]\n\t\t\t\t,src.[relationship_manager_id]\n\t\t\t\t,src.[date]\n\t\t\t\t,src.[deposit_amount]\n\t\t\t\t);\nEND\nGO\n\n\n\n/*    \n    Show database objects\n*/\nSELECT *\nFROM sys.objects\nWHERE is_ms_shipped = 0\nORDER BY [name];\n\n\n\n\n-- In a nutshell, the database schema is setup to process new customer data every day. \n-- This new data in the stage schema is upserted into the final table in the active schema. \n-- The watermark table allows the ETL program to be restarted to a prior date and hour at will. \n-- Now that we have the relational database schema worked out, we can focus on designing an Azure Synapse Pipeline\n-- to automate the reading of data from data lake storage and the writing of data to the final active table.\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "GlobomanticsDWH",
						"poolName": "GlobomanticsDWH"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/GlobomanticsDWH')]",
			"type": "Microsoft.Synapse/workspaces/sqlPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"collation": "SQL_Latin1_General_CP1_CI_AS",
				"maxSizeBytes": 263882790666240,
				"restorePointInTime": "0001-01-01T00:00:00",
				"annotations": []
			},
			"dependsOn": [],
			"location": "westeurope"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 1')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT TOP (100) [BranchID]\n,[RmFirstName]\n,[RmLastName]\n,[LastUpdateDate]\n,[RmID]\n FROM [dbo].[relations_manager]",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "GlobomanticsDWH",
						"poolName": "GlobomanticsDWH"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		}
	]
}